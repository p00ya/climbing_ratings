# Functions for pre-processing ascents data.

# Copyright Contributors to the Climbing Ratings project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

library(dplyr)
library(stringr)


# Converts an ascent type like "Hang dog" to a code like "dog".  The codes
# are all lower-case and contain no spaces.
NormalizeAscentType <- function(ascent_type) {
  ascent_type %>%
    str_to_lower() %>%
    str_remove_all(fixed(" ")) %>%
    recode(hangdog = "dog")
}

# Coerces x[[i]] to an integer, replacing NULL with NA.
AsIntegerOrNA <- function(x, idx = 1) {
  ifelse(is.null(x), NA, as.integer(x[[idx]]))
}

# Coerces x[[i]] to a character, replacing NULL with NA.
AsCharacterOrNA <- function(x, idx = 1) {
  ifelse(is.null(x), NA, as.character(x[[idx]]))
}

# Converts the list-of-singleton-integer-list structures typical of jsonlite to
# an atomic vector of integers.  NULLs are converted to NA.
FlattenInt <- function(lst, idx = 1) {
  purrr::map_int(lst, AsIntegerOrNA, idx = idx)
}

# Converts the list-of-singleton-character-list structures typical of jsonlite
# to an atomic vector of characters.  NULLs are converted to NA.
FlattenChr <- function(lst, idx = 1) {
  purrr::map_chr(lst, AsCharacterOrNA, idx = idx)
}

# Reads a CSV export of a climber's logbook from theCrag.  The filename is
# assumed to be in the format generated by theCrag, i.e.
# "climbername-logbook-YYYY-MM-DD.csv".
# Returns a "raw ascents" data frame with columns "ascentId", "route",
# "climber", "tick", "grade" and "timestamp".
ReadLogbook <- function(filename) {
  m <- str_match(basename(filename), "([^-]+)-logbook-\\d{4}-\\d{2}-\\d{2}")
  climber <- str_to_lower(m[[1, 2]])
  df <- read.csv(
    filename,
    # R doesn't support 64-bit integers, so force IDs to be interpreted as characters.
    colClasses = c(Ascent.ID = "character", Route.ID = "character"),
    stringsAsFactors = FALSE
  )
  df %>%
    select(Ascent.ID, Ascent.Type, Route.ID, Route.Grade, Ascent.Date) %>%
    mutate(
      route = factor(Route.ID),
      climber = climber,
      tick = factor(NormalizeAscentType(Ascent.Type)),
      grade = as.integer(Route.Grade),
      timestamp = as.integer(
        as.POSIXct(Ascent.Date, format = "%FT%H:%M:%SZ", optional = TRUE)
      )
    ) %>%
    na.omit() %>%
    select(ascentId = Ascent.ID, route, climber, tick, grade, timestamp)
}

# Reads all logbooks in directory "dir".  Logbook filenames are assumed to be
# in the format generated by theCrag, i.e. "climbername-logbook-YYYY-MM-DD.csv".
# Returns a "raw ascents" data frame with columns "ascentId", "route",
# "climber", "tick", "grade" and "timestamp".
ReadLogbooks <- function(dir) {
  logbooks <- Sys.glob(file.path(dir, "*-logbook-*.csv"))
  dfs <- purrr::map(logbooks, ReadLogbook)
  bind_rows(dfs)
}

# Downloads ascent data from theCrag's ascent facet API.  The data is paginated
# and saved as JSON responses in "dir".
FetchJsonAscentsFromApi <- function(area, api_key, dir, start = 1, per_page = 5000) {
  flatten_param <- paste(
    "data[numberAscents", "page", "perPage", "ascents[id", "route[id]",
    "account[id]", "tick[label]", "gradeID", "gradeScore", "date",
    "pitch[number", "tick[label]]]]",
    sep = ","
  )
  base_url <- paste0(
    "https://sandpit.thecrag.com/api",
    "/facet/ascents/at/", area,
    "/with-route-gear-style/sport",
    "/in-setting/natural",
    "?key=", api_key,
    "&flatten=", flatten_param,
    "&sortby=when",
    "&perPage=", per_page
  )

  for (page in start:1024) {
    url <- paste0(base_url, "&page=", page)
    filename <- file.path(dir, sprintf("ascents-%03d.json", page))

    if (download.file(url, filename, method = "libcurl")) {
      # Stop making requests if there was an error.
      warning(paste("Error downloading URL: ", url))
      break
    }

    j <- jsonlite::read_json(filename)
    names(j) <- "data"
    names(j$data) <- c("numberAscents", "page", "perPage", "ascents")
    # Note the perPage parameter of the request may not be respected; calculate
    # the actual pagination from the response.  The response may code these
    # fields as strings.
    j_num_ascents <- as.integer(j$data$numberAscents)
    j_page <- as.integer(j$data$page)
    j_per_page <- as.integer(j$data$perPage)
    # Stop on the last page.
    if (j_page * j_per_page >= j_num_ascents) {
      break
    }

    # Don't hammer theCrag's servers.
    Sys.sleep(1)
    page <- page + 1
  }
}

# Parses ascent data from JSON responses as returned by theCrag's ascent facet
# API.   "json" should be a parsed JSON object as returned by using jsonlite to
# parse the files written by "FetchJsonAscentsFromApi".
#
# Returns a "raw ascents" data frame with columns "ascentId", "route",
# "climber", "tick", "grade" and "timestamp".
ParseJsonAscents <- function(json) {
  names(json) <- "data"
  names(json$data) <- c("numberAscents", "page", "perPage", "ascents")

  # Due to the input JSON's use of heterogeneous arrays, what comes out of
  # jsonlite is horribly structured: ascents is a list, each ascent is a list,
  # and the fields have no names.
  df_json <- as.data.frame(
    do.call(rbind, json$data$ascents),
    stringsAsFactors = FALSE
  )
  # These columns must be consistent with the "flatten"
  colnames(df_json) <-
    c(
      "id", "routeID", "accountID", "tick", "gradeID", "gradeScore",
      "date", "pitch"
    )
  df_json %>%
    transmute(
      ascentId = FlattenChr(id),
      route = FlattenChr(routeID),
      tick = NormalizeAscentType(FlattenChr(tick)),
      climber = FlattenChr(accountID),
      timestamp = suppressWarnings(as.integer(
        as.POSIXct(FlattenChr(date), format = "%FT%H:%M:%SZ", optional = TRUE)
      )),
      grade = FlattenInt(gradeScore),
      pitch
    ) %>%
    purrr::pmap_dfr(
      function(ascentId, route, tick, climber, timestamp, grade, pitch, ...) {
        if (is.null(pitch)) {
          return(
            data.frame(
              ascentId, tick, grade, climber, timestamp, route,
              stringsAsFactors = FALSE
            )
          )
        }
        # Split an ascent of a multipitch route into multiple ascents
        # corresponding to each pitch.  Suffix the ascent and route IDs, e.g.
        # with a "P2" suffix for pitch 2.
        purrr::map_dfr(pitch, function(p) {
          data.frame(
            pitch.number = AsIntegerOrNA(p, 1),
            pitch.tick = AsCharacterOrNA(p, 2),
            stringsAsFactors = FALSE
          )
        }) %>%
          na.omit() %>%
          transmute(
            ascentId = paste0(ascentId, "P", pitch.number),
            tick = NormalizeAscentType(unlist(pitch.tick)),
            route = paste0(route, "P", pitch.number),
            grade = grade,
            climber = climber,
            timestamp = timestamp
          )
      }
    )
}

# Reads all ascent JSON in directory "dir".  JSON filenames are assumed to have
# the pattern "ascents-*.json".
# Returns a "raw ascents" data frame with columns "ascentId", "route",
# "climber", "tick", "grade" and "timestamp".
ReadAllJsonAscents <- function(dir) {
  responses <- Sys.glob(file.path(dir, "ascents-*.json"))
  purrr::map(responses, jsonlite::read_json) %>%
    purrr::map(ParseJsonAscents) %>%
    bind_rows() %>%
    mutate(
      route = factor(route),
      climber = factor(climber),
      tick = factor(tick)
    )
}

# Classifies tick types like "dog" into a logical indicating whether the
# ascent was clean, or NA.
#
# Note that we have pessimistic interpretations of some tick types that are
# ambiguous in practice, e.g. a plain "tick" is not counted as clean.
# Furthermore, no tick shift is applied - a clean top rope ascent is equivalent
# to an onsight.
IsTickClean <- function(ticktype) {
  # See https://www.thecrag.com/en/article/ticktypes
  case_when(
    ticktype %in% c(
      "onsight", "flash", "redpoint", "groundupredpoint",
      "pinkpoint", "clean", "onsightsolo", "topropeonsight", "topropeflash",
      "topropeclean", "secondclean", "leadsolo", "firstfreeascent"
    ) ~ TRUE,
    ticktype %in% c(
      "dog", "attempt", "retreat", "working",
      "allfreewithrest", "toproperest", "ghost", "secondrest"
    ) ~ FALSE
  )
}

# Tidies a raw ascents table.
#
# Removes unclassifiable ascents, removes routes with less than 2 ascents, adds
# a "clean" column, and re-orders the route levels so the first route has the
# most ascents at the most common grade.
#
# Also prints a summary of the resulting data.
#
# df_raw is expected to have the columns "ascentId", "route", "climber",
# "tick", "grade", "timestamp".
CleanAscents <- function(df_raw, min_time = 0L, max_time = NULL) {
  max_time <- ifelse(
    is.null(max_time),
    as.integer(Sys.time()) + 86400L, # + 1 day
    max_time
  )

  df <- df_raw %>%
    mutate(clean = IsTickClean(tick)) %>%
    filter(!is.na(clean)) %>%
    filter(!is.na(grade)) %>%
    filter(min_time <= timestamp) %>%
    filter(timestamp < max_time)

  # Summarise routes by their grade and number of ascents:
  routes <- df %>%
    group_by(route) %>%
    summarise(n = n(), grade = floor(median(grade)))

  # Make the route with the most ascents for the most common grade the first
  # route.  This means it will be used as the reference route (natural rating
  # prior with mode 0).  Having the most common grade and lots of ascents means
  # it is (hopefully) a good reference point.
  route_grades <- routes %>% count(grade)
  routes <- routes %>%
    inner_join(route_grades, by = "grade", suffix = c(".ascents", ".grade")) %>%
    arrange(desc(n.grade), desc(n.ascents)) %>%
    select(-n.grade, -grade)

  # Drop ascents where the route has a single ascent.
  df <- df %>%
    inner_join(routes, by = "route") %>%
    filter(n.ascents > 1) %>%
    select(-n.ascents)

  # Find how often climbers log clean ascents:
  climbers <- df %>%
    group_by(climber) %>%
    summarise(clean_p = mean(clean))

  # Drop ascents where the climber hasn't logged any non-clean ascents.
  df <- df %>%
    inner_join(filter(climbers, clean_p < 1), by = "climber") %>%
    select(-clean_p)

  # Recompute factors from the preprocessed data.
  df <- df %>%
    mutate(
      route = route %>%
        droplevels() %>%
        relevel(ref = as.character(routes[[1, 1]])),
      climber = climber %>% droplevels()
    )

  df
}

# Given a data frame containing ascents (as produced by "CleanAScents"),
# return a summary as a character.
SummarizeAscents <- function(df) {
  paste(
    prettyNum(nrow(df), big.mark = ","), "ascents by",
    prettyNum(nlevels(df$climber), big.mark = ","), "climbers, over",
    prettyNum(nlevels(df$route), big.mark = ","), "routes;",
    sprintf("%0.2f%%", mean(df$clean) * 100.0), "clean ascents\n"
  )
}

# Given a data frame containing filtered ascents (as produced by
# "CleanAscents"), normalizes these to ascent, page and route tables.
#
# period_length is the number of seconds per page.
NormalizeTables <- function(df, period_length) {
  df_routes <- df %>%
    group_by(route) %>%
    summarise(grade = floor(median(grade)))

  df_ascents <- df %>%
    mutate(
      t = (timestamp - min(!!df$timestamp)) %/% period_length,
      clean = as.numeric(clean)
    ) %>%
    arrange(climber, t)

  df_pages <- df_ascents %>%
    group_by(climber, t) %>%
    summarise(timestamp = first(timestamp))

  # Set first_page[c] to be the index in df_pages of the first page for climber
  # c.
  first_page <- (df_pages %>% group_by(climber) %>% summarise(n = n()) %>%
    mutate(idx = head(cumsum(c(1, n)), -1)))$idx

  df_pages <- df_pages %>%
    ungroup() %>%
    mutate(page = row_number()) %>%
    select(climber, t, page, timestamp)

  df_ascents <- df_ascents %>%
    inner_join(df_pages, by = c("climber", "t")) %>%
    select(route, climber, clean, page)

  list(ascents = df_ascents, pages = df_pages, routes = df_routes)
}

# Performs a transformation of a grade to a natural rating.
#
# The reference grade "ref" is normalized to a natural rating of 0.
#
# This transformation assumes a linear relationship between the grade and the
# "natural" rating.  A scale of 1 implies that if a climber has a 50%
# probability of ascending a route at grade X cleanly, then they have a 1/(1+e)
# (approx. 27%) probability of ascending a route at grade X + 1 cleanly.
TransformGrade <- function(grade, scale = 0, ref = grade[[1]]) {
  scale * (grade - ref)
}

# Writes normalized tables to CSV files.
#
# The files are written with standard names to the directory specified by
# "dir".
#
# "dfs" should be a list of data frames, with the tags "ascents", "routes" and
# "pages"; like what NormalizeTables returns.
WriteNormalizedTables <- function(dfs, dir) {
  write.csv(
    dfs$ascents %>%
      mutate(route = as.integer(route) - 1, page = page - 1) %>%
      select(-climber),
    file.path(dir, "ascents.csv"),
    row.names = FALSE
  )
  write.csv(
    dfs$routes %>% select(route, rating),
    file.path(dir, "routes.csv"),
    row.names = FALSE
  )
  write.csv(
    dfs$pages %>%
      select(climber, timestamp = t) %>%
      mutate(climber = as.integer(climber) - 1),
    file.path(dir, "pages.csv"),
    row.names = FALSE
  )
}
