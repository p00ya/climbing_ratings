# Functions for pre-processing ascents data.

# Copyright 2019 Dean Scarff
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

library(dplyr)
library(stringr)


# Converts an ascent type like "Hang dog" to a code like "dog".  The codes
# are all lower-case and contain no spaces.
NormalizeAscentType <- function(ascent_type) {
  ascent_type %>%
    str_to_lower() %>%
    str_remove_all(fixed(" ")) %>%
    recode(hangdog = "dog")
}

# Appends NAs to each element of x such that they all have at least len
# elements.
PadList <- function(x, len) {
  purrr::map_if(x, ~ length(.) < len, ~ c(., rep(NA, len - length(.))))
}

# Converts a list of grades as they appear in theCrag's API responses to an
# atomic vector of integers representing the Ewbank grade.  Each input grade is
# expected to be a list containing (id, grade, context).  Contexts other than
# AU will return NA.
ExtractEwbankGrade <- function(grades) {
  # Empty lists are dropped by rbind; replace them with the right shape of
  # list containing NA.
  grades <- PadList(grades, 3)

  dfg <- as.data.frame(do.call(rbind, grades))
  colnames(dfg) <- c("id", "grade", "context")
  # Ignore "NAs introduced by coercion" warnings.
  suppressWarnings(ifelse(dfg$context == "AU", as.integer(dfg$grade), NA))
}

# Reads a CSV export of a climber's logbook from theCrag.  The filename is
# assumed to be in the format generated by theCrag, i.e.
# "climbername-logbook-YYYY-MM-DD.csv".
# Returns a "raw ascents" data frame with columns "ascentId", "route",
# "climber", "tick", "grade" and "timestamp".
ReadLogbook <- function(filename) {
  m <- str_match(basename(filename), "([^-]+)-logbook-\\d{4}-\\d{2}-\\d{2}")
  climber <- str_to_lower(m[[1, 2]])
  df <- read.csv(
    filename,
    # R doesn't support 64-bit integers, so force IDs to be interpreted as characters.
    colClasses = c(Ascent.ID = "character", Route.ID = "character"),
    stringsAsFactors = FALSE
  )
  df %>%
    select(Ascent.ID, Ascent.Type, Route.ID, Route.Grade, Ascent.Date) %>%
    mutate(
      route = factor(Route.ID),
      climber = climber,
      tick = factor(NormalizeAscentType(Ascent.Type)),
      grade = as.integer(Route.Grade),
      timestamp = as.integer(
        as.POSIXct(Ascent.Date, format = "%FT%H:%M:%SZ", optional = TRUE)
      )
    ) %>%
    na.omit() %>%
    select(ascentId = Ascent.ID, route, climber, tick, grade, timestamp)
}

# Reads all logbooks in directory "dir".  Logbook filenames are assumed to be
# in the format generated by theCrag, i.e. "climbername-logbook-YYYY-MM-DD.csv".
# Returns a "raw ascents" data frame with columns "ascentId", "route",
# "climber", "tick", "grade" and "timestamp".
ReadLogbooks <- function(dir) {
  logbooks <- Sys.glob(file.path(dir, "*-logbook-*.csv"))
  dfs <- purrr::map(logbooks, ReadLogbook)
  bind_rows(dfs)
}

# Parses ascent data from JSON responses as returned by theCrag API:
# http://www.thecrag.com/api/facet/ascents/?thin=1&withdata=AscentID,CreateDate,Date,LastUpdated,AccountID,NodeID,Tick,Label,Artificial,Grade,AltGrade,Height,Pitch,Quality,Shot&markupType=text
# Returns a "raw ascents" data frame with columns "ascentId", "route",
# "climber", "tick", "grade" and "timestamp".
ReadJsonAscents <- function(filename) {
  j <- jsonlite::read_json(filename)

  # Due to the input JSON's use of heterogeneous arrays, what comes out of
  # jsonlite is horribly structured: ascents is a list, each ascent is a list,
  # ascents can have different lengths, and the fields in each ascent have no
  # names.
  ascents <- PadList(j$data$ascents, 15)
  df_json <- as.data.frame(do.call(rbind, ascents))

  # Columns correspond to the "withdata" parameter of the API request.
  colnames(df_json) <- c(
    "AscentID", "CreateDate", "Date", "LastUpdated", "AccountID", "NodeID",
    "Tick", "Label", "Artificial", "Grade", "AltGrade", "Height", "Pitch",
    "Quality", "Shot"
  )

  df_json %>%
    filter(Artificial == 0) %>%
    transmute(
      # Don't coerce the IDs to factors; assume this will be done in
      # ReadAllJsonAscents after rbind'ing.
      ascentId = as.character(AscentID),
      route = as.character(NodeID),
      climber = as.character(AccountID),
      tick = NormalizeAscentType(Tick),
      grade = ExtractEwbankGrade(Grade),
      timestamp = suppressWarnings(as.integer(
        as.POSIXct(as.character(Date), format = "%FT%H:%M:%SZ", optional = TRUE)
      ))
    ) %>%
    na.omit()
}

# Reads all ascent JSON in directory "dir".  JSON filenames are assumed to have
# the pattern "ascents-*.json".
# Returns a "raw ascents" data frame with columns "ascentId", "route",
# "climber", "tick", "grade" and "timestamp".
ReadAllJsonAscents <- function(dir) {
  responses <- Sys.glob(file.path(dir, "ascents-*.json"))
  purrr::map(responses, ReadJsonAscents) %>%
    bind_rows() %>%
    mutate(
      route = factor(route),
      climber = factor(climber),
      tick = factor(tick)
    )
}

# Classifies tick types like "dog" into a logical indicating whether the
# ascent was clean, or NA.
# Note that we are optimistic about tick types that are ambiguous in practice,
# e.g. a plain "tick" is clean.
# Also note that no tick shift is applied - a clean top rope ascent is
# equivalent to an onsight.
IsTickClean <- function(ticktype) {
  # See https://www.thecrag.com/en/article/ticktypes
  case_when(
    ticktype %in% c(
      "onsight", "flash", "redpoint", "groundupredpoint",
      "pinkpoint", "clean", "onsightsolo", "topropeonsight", "topropeflash",
      "topropeclean", "secondclean", "leadsolo", "firstfreeascent",
      "tick", "second"
    ) ~ TRUE,
    ticktype %in% c(
      "dog", "attempt", "retreat", "working",
      "allfreewithrest", "toproperest", "ghost", "secondrest"
    ) ~ FALSE
  )
}

# Tidies a raw ascents table.
#
# Removes unclassifiable ascents, removes routes with less than 2 ascents, adds
# a "clean" column, and re-orders the route levels so the most popular route is
# first.
#
# Also prints a summary of the resulting data.
#
# df_raw is expected to have the columns "ascentId", "route", "climber",
# "tick", "grade", "timestamp".
CleanAscents <- function(df_raw) {
  df <- df_raw %>%
    mutate(clean = IsTickClean(tick)) %>%
    filter(!is.na(clean)) %>%
    filter(!is.na(grade))

  # Find the most popular routes:
  top_routes <- count(df, route, sort = TRUE)

  # Drop ascents where the route has a single ascent.
  df <- df %>%
    inner_join(top_routes, by = "route") %>%
    filter(n > 1) %>%
    select(-n)

  # Make the route with the most ascents the "first" route.  This means it will
  # be used as the reference route (rating of 1).  Having lots of ascents
  # means it is (hopefully) a good reference point for comparing climbers.
  df <- df %>%
    mutate(
      route = route %>%
        droplevels() %>%
        relevel(ref = as.character(top_routes[[1, 1]])),
      climber = climber %>% droplevels()
    )

  # Summarize the tick counts.
  cat(
    nrow(df), "ascents by",
    nlevels(df$climber), "climbers over",
    nlevels(df$route), "routes;",
    sprintf("%0.2f%%", mean(df$clean) * 100.0), "clean ascents\n"
  )

  df
}

# Given a data frame containing filtered ascents (as produced by
# "CleanAscents"), normalizes these to ascent, page and route tables.
#
# period_length is the number of seconds per page.
NormalizeTables <- function(df, period_length) {
  df_routes <- df %>%
    group_by(route) %>%
    summarise(ewbank = floor(median(grade)))

  df_ascents <- df %>%
    mutate(
      t = (timestamp - min(df$timestamp)) %/% period_length,
      clean = as.numeric(clean)
    ) %>%
    arrange(climber, t)

  df_pages <- df_ascents %>%
    group_by(climber, t) %>%
    summarise(timestamp = first(timestamp))

  # Set first_page[c] to be the index in df_pages of the first page for climber
  # c.
  first_page <- (df_pages %>% group_by(climber) %>% summarise(n = n()) %>%
    mutate(idx = head(cumsum(c(1, n)), -1)))$idx

  # time relative to the first ascent from the same climber
  df_pages$rel_t <- df_pages$t - df_pages$t[first_page[df_pages$climber]]
  # time relative to the next page for the same climber (meaningless for last
  # page of each climber).
  df_pages$gap <- c(diff(df_pages$rel_t), 0)

  df_pages <- df_pages %>%
    ungroup() %>%
    mutate(page = row_number()) %>%
    select(climber, t, gap, page, timestamp)

  df_ascents <- df_ascents %>%
    inner_join(df_pages, by = c("climber", "t")) %>%
    select(route, climber, clean, page)

  list(ascents = df_ascents, pages = df_pages, routes = df_routes)
}

# Performs a transformation of a grade to a "gamma" rating.
#
# The first rating is normalized to 1 (a natural rating of 0).
#
# This transformation assumes a linear relationship between the grade and the
# "natural" rating.  A scale of 1 implies that if a climber has a 50%
# probability of ascending a route at grade X cleanly, then they have a 1/(1+e)
# (approx. 27%) probability of ascending a route at grade X + 1 cleanly.
TransformGrade <- function(grade, scale = 0) {
  exp(scale * (grade - grade[[1]]))
}

# Writes normalized tables to CSV files.
#
# The files are written with standard names to the directory specified by
# "dir".
#
# "dfs" should be a list of data frames, with the tags "ascents", "routes" and
# "pages"; like what NormalizeTables returns.
WriteNormalizedTables <- function(dfs, dir) {
  write.csv(
    dfs$ascents %>%
      mutate(route = as.integer(route) - 1, page = page - 1) %>%
      select(-climber),
    file.path(dir, "ascents.csv"),
    row.names = FALSE
  )
  write.csv(
    dfs$routes %>% select(route, grade),
    file.path(dir, "routes.csv"),
    row.names = FALSE
  )
  write.csv(
    dfs$pages %>%
      select(climber, gap) %>%
      mutate(climber = as.integer(climber) - 1),
    file.path(dir, "pages.csv"),
    row.names = FALSE
  )
}
